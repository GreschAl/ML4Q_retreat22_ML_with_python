{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "possible-truck",
   "metadata": {
    "id": "possible-truck"
   },
   "source": [
    "# Notebook 1: Structuring data without Neural Networks\n",
    "\n",
    "**Authors:** Kenny Choo, Mark H. Fischer, Eliska Greplova for the conference \"Summer School: ML in Quantum Physics and Chemistry\" (24.08.-03.09.2021, Warsaw)\n",
    "\n",
    "Adapted for the ML4Q-retreat 2022 by Alexander Gresch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44K0-SShu7X3",
   "metadata": {
    "id": "44K0-SShu7X3"
   },
   "outputs": [],
   "source": [
    "# Helper Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rYL08R8jrUpF",
   "metadata": {
    "id": "rYL08R8jrUpF"
   },
   "source": [
    "## Step 0. Loading and saving files with Google Colaboratory\n",
    "\n",
    "Within these tutorials, we will need to upload some data (in particular, training data). E.g., today, we will upload Monte Carlo generated configurations of Ising spins on a 30x30 lattice. To upload data, you can pick one out of the three options (also, mix them freely):\n",
    "\n",
    "- **Option A**. *Downloading data onto your Google drive and mounting the Google drive to this Colab notebook.*\n",
    "\n",
    "\"Mounting\" means giving a temporary permission to a specific Colab notebook which enables browsing, loading, and saving files on your Google drive from this specific notebook. Once you exit the notebook, the perimission is gone, and you need to mount the Google drive again. Mounting is accompanied by an additional log-in to your Gmail account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eApxNcEOtqkH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eApxNcEOtqkH",
    "outputId": "7065ca30-35ea-4005-e07e-ea27a6c96a7d"
   },
   "outputs": [],
   "source": [
    "# Option A.\n",
    "# Mount your Google Drive:\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g53rdXvzutr2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "g53rdXvzutr2",
    "outputId": "88e16bb5-1b5e-47d7-99b5-b45ad8f4f36b"
   },
   "outputs": [],
   "source": [
    "# Option A.\n",
    "# Folder where you store the data (change if desired)\n",
    "folder = '/content/drive/MyDrive/Colab Notebooks/retreat/'\n",
    "\n",
    "# Access the data with simple commands:\n",
    "ising_training_configs = np.load(folder + \"/Ising/ising_training_configs_30x30.npy\")\n",
    "\n",
    "# You can also save them there:\n",
    "x = np.array([0,1])\n",
    "np.save(folder + \"/first_save\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A0Bc_uCRPsfG",
   "metadata": {
    "id": "A0Bc_uCRPsfG"
   },
   "source": [
    "- **Option B.** *Clone the GitHub repository*\n",
    "\n",
    "If you want to avoid working with Google drive, you can use this work-around. All needed data are on [this GitHub](https://github.com/GreschAl/ML4Q_retreat22_ML_with_python). You can clone this GitHub repository into your Colab environment in the same way as you would in your local machine, using git clone. Once the repository is cloned, refresh the file-explorer on the left to browse through its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DtMKirDKQLW3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DtMKirDKQLW3",
    "outputId": "952d3967-983d-4eb8-f64d-604e9ea90ccc"
   },
   "outputs": [],
   "source": [
    "# Option B.\n",
    "!git clone https://github.com/GreschAl/ML4Q_retreat22_ML_with_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mgorAcwwQwZJ",
   "metadata": {
    "id": "mgorAcwwQwZJ"
   },
   "outputs": [],
   "source": [
    "# Option B.\n",
    "folder = \"/content/ML4Q_retreat22_ML_with_python/exercises/Ising_data\"\n",
    "# Access the data with simple commands:\n",
    "ising_training_configs = np.load(folder + \"/ising_training_configs_30x30.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6L_cH6L3QL54",
   "metadata": {
    "id": "6L_cH6L3QL54"
   },
   "source": [
    "Take note these are local and temporary files, and will disappear after closing the notebook. For saving and loading data from your local machine, look at Option C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tBzzVvg2tq6I",
   "metadata": {
    "id": "tBzzVvg2tq6I"
   },
   "source": [
    "- **Option C.** *Downloading data onto your local machine and loading/saving data onto your local computer*\n",
    "\n",
    "For saving and loading data from your local machine, you will need 'google.colab' library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iqFIeepqMdge",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "iqFIeepqMdge",
    "outputId": "29614c9a-fa22-4716-8595-0c377f336737"
   },
   "outputs": [],
   "source": [
    "# Option C.\n",
    "from google.colab import files\n",
    "\n",
    "# Saving data on your local machine:\n",
    "x = np.array([0,1])\n",
    "np.save('trial', x)\n",
    "files.download('trial.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78op-DswNak3",
   "metadata": {
    "id": "78op-DswNak3"
   },
   "outputs": [],
   "source": [
    "# Option C.\n",
    "# Loading data from your local machine:\n",
    "files.upload()  # it opens the file explorer where you can pick which files to upload \n",
    "                # (names stay the same as local ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7niEuj98UGkc",
   "metadata": {
    "id": "7niEuj98UGkc"
   },
   "source": [
    "Now we are ready to look at the data set!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-minutes",
   "metadata": {
    "id": "reserved-minutes"
   },
   "source": [
    "# Example #1: Ising Spin Configuration Classification\n",
    "\n",
    "\n",
    "The Ising model is given by the (classical) Hamiltonian:\n",
    "\n",
    "\\begin{align}\n",
    "H(\\boldsymbol{\\sigma}) = -\\sum_{<ij>} \\sigma_{i}\\sigma_{j},\n",
    "\\end{align}\n",
    "where the spins $\\sigma_{i} \\in \\lbrace -1, 1 \\rbrace$ are binary variables living on the vertices of a square lattice and the sum is taken over nearest neighbours $<ij>$. We have set $J=1$.\n",
    "  \n",
    "At a given temperature $\\beta = 1/T$, the probability of a configuration $\\sigma$ is given by the Boltzmann distribution\n",
    "  \n",
    "\\begin{align}\n",
    "  P(\\boldsymbol{\\sigma}) = \\frac{e^{-\\beta H(\\boldsymbol{\\sigma})}}{Z},\n",
    " \\end{align}\n",
    "  \n",
    "  where $Z$ is the partition function. This model exhibits a phase transition from the ferromagnetic phase at low tempertures to a paramagnetic phase at high temperatures. The transition temperature is $T_c \\approx 2.2692$.\n",
    "  \n",
    "  **Task**\n",
    " \n",
    "1.   Classify the ferromagnetic versus the paramagnetic phase of the Ising model\n",
    "2.   Find the transition temperature\n",
    "  \n",
    "**Dataset**: Monte Carlo generated configurations on a 30x30 square lattice. The configuration are labelled by temperature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-norway",
   "metadata": {
    "id": "above-norway"
   },
   "source": [
    "## Step 1: Import data and analyze the data shape\n",
    "\n",
    "The folder `Ising_data` contains Monte Carlo generated Ising configurations on the two-dimensional lattice. The data set is divided into training and test parts and corresponding label files containing the temperature, $T$, of each Monte Carlo sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-stylus",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "outstanding-stylus",
    "outputId": "a8643e4c-af7e-456b-8524-495eb81eeaac"
   },
   "outputs": [],
   "source": [
    "N = 30 # linear dimension of the lattice \n",
    "\n",
    "ising_training_configs = np.load(folder + \"/ising_training_configs_{0}x{0}.npy\".format(N))\n",
    "ising_training_labels = np.load(folder + \"/ising_training_labels_{0}x{0}.npy\".format(N))\n",
    "ising_test_configs = np.load(folder + \"/ising_test_configs_{0}x{0}.npy\".format(N))\n",
    "ising_test_labels = np.load(folder + \"/ising_test_labels_{0}x{0}.npy\".format(N))\n",
    "\n",
    "print('train_images.shape =', ising_training_configs.shape)\n",
    "print('train_labels.shape =', ising_training_labels.shape)\n",
    "print('test_images.shape =', ising_test_configs.shape)\n",
    "print('test_labels.shape =', ising_test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-economy",
   "metadata": {
    "id": "sharp-economy"
   },
   "source": [
    "We see that we have a training set of size 1000 and a test set of size 1000.\n",
    "\n",
    "Each image is a 30x30 array which takes values in {-1, 1}. The labels of these images are the temperatures and they are in [1, 3.5]. Let us plot some data to understand it further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-calibration",
   "metadata": {
    "id": "elegant-calibration"
   },
   "outputs": [],
   "source": [
    "def plot_Ising_configuration(spins, ax=None):\n",
    "    '''\n",
    "    this is just a helper function to plot the configuration of spins given by argument 'spins'\n",
    "    '''\n",
    "    if ax == None:\n",
    "        print(\"problem\")\n",
    "        ax = plt.gca()\n",
    "    N = np.shape(spins)[1]\n",
    "\n",
    "    for i in range(N):\n",
    "        ax.plot([i, i], [0, N-1], 'k', zorder=0, linewidth=0.5)\n",
    "        ax.plot([0, N-1], [i,i], 'k', zorder=0, linewidth=0.5)\n",
    "\n",
    "    cmap = plt.cm.Blues\n",
    "    cmap2 = plt.cm.Oranges\n",
    "    cmap(1)\n",
    "    colors = [cmap2(140), cmap(220)] # note: orange is down, blue is up!\n",
    "    colors = [cmap(220), cmap2(140)] # note: blue is down, orange is up!\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            ax.add_patch(plt.Circle((i,j), radius=0.3, fc=colors[int((spins[i,j]+1)/2.)], zorder=2))\n",
    "\n",
    "    ax.axes.set_axis_off()\n",
    "    ax.set_ylim(-1, N+1)\n",
    "    ax.set_xlim(-1, N+1)\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-strike",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "korean-strike",
    "outputId": "0951fcc7-ab11-4d39-ce14-747879aef583"
   },
   "outputs": [],
   "source": [
    "which_training_point1 = 50\n",
    "which_training_point2 = 700\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(10, 30)\n",
    "fig.subplots_adjust(wspace=0.01,hspace=0.08, left=0.01, right=0.99, bottom=0.05, top=0.99)\n",
    "\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "plot_Ising_configuration(ising_training_configs[which_training_point1], ax1)\n",
    "ax1.set_title(\"T={:1.2f}\".format(ising_training_labels[which_training_point1]))\n",
    "ax1.title.set_position((0.5,-0.1))\n",
    "\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "plot_Ising_configuration(ising_training_configs[which_training_point2], ax2)\n",
    "ax2.set_title(\"T={:1.2f}\".format(ising_training_labels[which_training_point2]))\n",
    "ax2.title.set_position((0.5,-0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-shock",
   "metadata": {
    "id": "foreign-shock"
   },
   "source": [
    "## Step 2: Use standard techniques to see a structure in the data\n",
    "### Principal Component Analysis (PCA)\n",
    "\n",
    "PCA is a dimensionality reduction method - it finds the features that vary the most accross the data set and then transforms the basis such that these features can be analyzed.\n",
    "\n",
    "\n",
    "Here, we learn to do PCA on the above set of Ising configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-swedish",
   "metadata": {
    "id": "delayed-swedish"
   },
   "outputs": [],
   "source": [
    "# It is worth to implement it once by yourself, step by step.\n",
    "# After this one time, use libraries like sklearn or tensorflow ;)\n",
    "def pca(X=np.array([]), no_dims=50):\n",
    "    \"\"\"\n",
    "          Runs PCA on the array X (shape NxD, where D is the size of a flattened sample)\n",
    "          to reduce its dimensions to no_dims (usually start with no_dims=2, so you can visualize it easily)\n",
    "    \"\"\"\n",
    "     \n",
    "    ## We need to normalize our samples, e.g., make all pixel/site values across all samples have zero mean\n",
    "    # You can start by extracting the dimensions of your data, i.e., number of samples and shape of each sample\n",
    "    shape = X.shape\n",
    "\n",
    "    ########################################################################\n",
    "    ### TODO: ###\n",
    "    ########################################################################\n",
    "    # Calculate the mean value of each pixel/site of the configuration across all samples\n",
    "\n",
    "    # Then, we substract the mean of each site over all samples, such that each site has a mean value of 0.\n",
    "\n",
    "    ## Now we need to create the covariance matrix out of our data set\n",
    "\n",
    "    # Diagonalise the covariance matrix    \n",
    "\n",
    "    ## Finally, we take only the first 'no_dims' columns of the eigenvector matrix \n",
    "    ## and take the inner product with the input matrix X of all configurations.\n",
    "    ########################################################################\n",
    "\n",
    "    return inner_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kxm4-uBrZUI2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kxm4-uBrZUI2",
    "outputId": "e433a0fc-52f1-445e-e748-8a9d3596e104"
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "### TODO: ###\n",
    "########################################################################\n",
    "# First we reshape the data such that we are working with matrices: \n",
    "# We flatten the configurations of 30x30 into 900 vector and create matrix, X, of all 1000 configurations: \n",
    "# This has a dimension 1000x900.\n",
    "print(\"Before reshaping:\", ising_training_configs.shape)\n",
    "# X = ... \n",
    "print(\"After reshaping:\", X.shape)\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HEN_TEF3Znaj",
   "metadata": {
    "id": "HEN_TEF3Znaj"
   },
   "outputs": [],
   "source": [
    "# Now we can run our PCA on 1000 flattened samples\n",
    "PCA_coord = pca(X, no_dims=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-mitchell",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "postal-mitchell",
    "outputId": "38110f0d-ee0c-42ae-8849-f3d9a6ec1b66"
   },
   "outputs": [],
   "source": [
    "# Here we plot the data points in the coordinates of the first two principal components\n",
    "# with the color bar created using the temperature labels\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(7, 6)\n",
    "fig.subplots_adjust(wspace=0.01,hspace=0.01, left=0.20, right=0.9, bottom=0.15, top=0.94)\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "pca_plt = ax1.scatter(PCA_coord[:,0], PCA_coord[:,1], 10, ising_training_labels, \n",
    "            cmap=plt.cm.coolwarm)\n",
    "\n",
    "cbar = plt.colorbar(pca_plt, )\n",
    "cbar.set_label('Temperature, T')\n",
    "\n",
    "ax1.set_xlabel('PCA component 1')\n",
    "ax1.set_ylabel('PCA component 2')\n",
    "\n",
    "# fig.savefig('pca_test.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-change",
   "metadata": {
    "id": "innovative-change"
   },
   "source": [
    "### What we see in the plot?\n",
    "\n",
    "Try and think for yourself before seeing the solution :)\n",
    "E.g., how many clusters do you see and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8BDGnWG3jzZz",
   "metadata": {
    "id": "8BDGnWG3jzZz"
   },
   "source": [
    "The example above shows clear clusters. Thanks to the coloring the samples by the temperature that was used to generate them, we immediately see that the red, high temperature, cluster corresponds to the disordered phase and the light blue clusters on the boundaries correspond to two-types of ordered configurations: either all spins alighned up or all spins aligned down. It is possible to guess the value of the critical temperature from the color of the points placed between the clusters. Try to identify it and compare to the literature! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-contact",
   "metadata": {
    "id": "broadband-contact"
   },
   "source": [
    "# Example #2: Ising model with local constraints: Ising Gauge Theory (IGT)\n",
    "\n",
    "In the previous example, we classified spin configurations of the simple Ising model. That was a relatively easy task given that we know that there's a global order parameter, i.e., the magnetization that distinguishes the two phases the model has.\n",
    "\n",
    "In the following, we will look at spin configurations coming from a different model on which the simple PCA spectacularly fails. In this model, Ising spins live on the edges of a square lattice (see Figs. below). The Hamiltonian then favors even down and up spins around a square. If the number is odd, a pentalty is paid. The Hamiltonian is given by\n",
    "\n",
    "\\begin{align}\n",
    "H(\\boldsymbol{\\sigma}) = -\\sum_{p} \\prod_{i \\in p}\\sigma_{i},\n",
    "\\end{align}\n",
    "where we sum over the plaquettes $p$ of the square lattice.\n",
    "\n",
    "This model does not have a finite temperature transition. We thus want to train a network to distinguish the (highly degenerate) ground states of this system from any excited state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-saturday",
   "metadata": {
    "id": "overhead-saturday"
   },
   "source": [
    "First, we load and analyze the shape of our data set again. As before, they are located in the folder `Ising` and labeled by a temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-basic",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "innovative-basic",
    "outputId": "b2e623c5-dde0-4357-bdc3-b654436a1ca1"
   },
   "outputs": [],
   "source": [
    "N = 16 # linear dimension of the lattice \n",
    "\n",
    "ilgt_training_configs = np.load(folder + \"/ilgt_training_configs.npy\".format(N))\n",
    "ilgt_training_labels = np.load(folder + \"/ilgt_training_labels.npy\".format(N))\n",
    "ilgt_test_configs = np.load(folder + \"/ilgt_test_configs.npy\".format(N))\n",
    "ilgt_test_labels = np.load(folder + \"/ilgt_test_labels.npy\".format(N))\n",
    "\n",
    "print('train_images.shape =', ilgt_training_configs.shape)\n",
    "print('train_labels.shape =', ilgt_training_labels.shape)\n",
    "print('test_images.shape =', ilgt_test_configs.shape)\n",
    "print('test_labels.shape =', ilgt_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-celtic",
   "metadata": {
    "id": "indirect-celtic"
   },
   "outputs": [],
   "source": [
    "def plot_igt_configuration(spins, name, dual=False, save=False):\n",
    "    '''\n",
    "    this is just a helper function to plot the configuration of spins given by 'spins'\n",
    "    note that (i,j) denotes a vertex coordinate, such that the location of the plaquette\n",
    "    center is at (i+0.5, j+0.5) and thus, the x spin is at (i+1, j+0.5) etc.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spins  :  int\n",
    "        spin configuration, dimension is NxNx2\n",
    "    dual   :  bool\n",
    "        Plot the configuration in dual space or not. Default is False.\n",
    "    '''\n",
    "    N = np.shape(spins)[0]\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.add_axes()\n",
    "    ax = fig.axes[0]\n",
    "    # spins = (2*spins-1)\n",
    "    for i in range(N+1):\n",
    "        ax.plot([i, i], [0,N], 'k')\n",
    "        ax.plot([0,N], [i,i], 'k')\n",
    "\n",
    "    if not dual:\n",
    "        colors = ['#1329A4', '#F45A11'] # note: blue is down, gold is up!\n",
    "        for i in range(N):\n",
    "            fig.gca().add_patch(plt.Circle((0,i+0.5), radius=0.2, fc=colors[int((spins[-1,2*i]+1)/2.)]))\n",
    "            fig.gca().add_patch(plt.Circle((i+0.5,0), radius=0.2, fc=colors[int((spins[i,-1]+1)/2.)]))\n",
    "            for j in range(N):\n",
    "                fig.gca().add_patch(plt.Circle((i+1,j+0.5), radius=0.2, fc=colors[int((spins[i,2*j+0]+1)/2.)]))\n",
    "                fig.gca().add_patch(plt.Circle((i+0.5,j+1), radius=0.2, fc=colors[int((spins[i,2*j+1]+1)/2.)]))\n",
    "\n",
    "    if dual:\n",
    "        excitation = []\n",
    "        for i in range(N):\n",
    "            if spins[-1, 2*i+0]==1: ax.plot([-0.5, 0.5], [i+0.5, i+0.5], '#1329A4', lw=3)\n",
    "            if spins[i, -1]==1: ax.plot([i+0.5, i+0.5], [-0.5, 0.5], '#1329A4', lw=3)\n",
    "            for j in range(N):\n",
    "                j_up = (N+j-1)%N\n",
    "                i_left = (i+N-1)%N\n",
    "                if spins[i,2*j+0]==1: ax.plot([i+0.5, i+1.5], [j+0.5, j+0.5], '#1329A4', lw=3)\n",
    "                if spins[i,2*j+1]==1: ax.plot([i+0.5, i+0.5], [j+0.5, j+1.5], '#1329A4', lw=3)\n",
    "                if spins[i,2*j+0]*spins[i_left, 2*j+0]*spins[i,2*j+1]*spins[i,2*j_up+1]==-1: excitation.append([i+0.5,j+0.5])\n",
    "        if len(excitation)>0: plt.scatter(np.array(excitation)[:,0], np.array(excitation)[:,1], color='#F45A11', s=150, marker=(5,1))\n",
    "    ax.set_ylim(-1,N+1)\n",
    "    ax.set_xlim(-1,N+1)\n",
    "    ax.set_aspect('equal')\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(\"configuration_\" + name +\".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-century",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "biological-century",
    "outputId": "cbbc5413-8507-475a-9214-62b0165ae1d4"
   },
   "outputs": [],
   "source": [
    "# Notice indexing: (i,j) indexes plaquettes which have centers at (i+0.5, j+0.5).\n",
    "# (0,0) is the bottom left corner of the lattice!\n",
    "# Then you have two spin configurations.\n",
    "# First spin is one on the right side of the plaquette (i+1,j+0.5),\n",
    "# Second spin is one on the upper side of the plaquette (i+0.5,j+1)\n",
    "print(ilgt_training_configs[0][0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-machine",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "id": "brave-machine",
    "outputId": "ba2cf63f-4c23-4bcf-be59-3f01cebac5e3"
   },
   "outputs": [],
   "source": [
    "# Let's plot the chosen sample. But first we need to reshape the data so the plotting procedure works\n",
    "N = ilgt_training_configs[0].shape[0] # size of the lattice\n",
    "# Pick one sample and reshape it to flatten the two sublattices (so you have N rows of 2*N spins)\n",
    "sample = 0\n",
    "spins = np.reshape(ilgt_training_configs[sample],[N,2*N])\n",
    "\n",
    "#plt configuration\n",
    "plot_igt_configuration(spins,'igt0')\n",
    "\n",
    "#plot the dual mapping\n",
    "plot_igt_configuration(spins,'igt0_dual',dual=True)\n",
    "#ax1.set_title(\"T={:1.2f}\".format(ising_training_labels[250]))\n",
    "#ax1.title.set_position((0.5,-0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-neutral",
   "metadata": {
    "id": "lucky-neutral"
   },
   "source": [
    "Now we repeat PCA on the IGT traing data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-reunion",
   "metadata": {
    "id": "familiar-reunion"
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "### TODO: ###\n",
    "########################################################################\n",
    "# firstly, flatten your data:\n",
    "#X_ilgt = ...\n",
    "########################################################################\n",
    "PCA_coord_ILGT = pca(X_ilgt, no_dims=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Nt7BH6snkeXi",
   "metadata": {
    "id": "Nt7BH6snkeXi"
   },
   "source": [
    "#### Reshaping is not trivial, so here you have the solution if you're out of ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b5LJEakpw0",
   "metadata": {
    "id": "38b5LJEakpw0"
   },
   "outputs": [],
   "source": [
    "X_ilgt = np.reshape(ilgt_training_configs, (ilgt_training_configs.shape[0], N*N*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OLA32uJukvvf",
   "metadata": {
    "id": "OLA32uJukvvf"
   },
   "source": [
    "### Plotting again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-irish",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "brief-irish",
    "outputId": "6e936b46-4449-4b3d-fb83-bd36d17f3ca5"
   },
   "outputs": [],
   "source": [
    "# Here we plot the data points in the coordinates of the first two principal components\n",
    "# with the color bar created using the temperature labels\n",
    "\n",
    "fig = plt.figure(dpi=200)\n",
    "fig.set_size_inches(3.40457, 3)\n",
    "fig.subplots_adjust(wspace=0.01,hspace=0.01, left=0.20, right=0.9, bottom=0.15, top=0.94)\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "pca_plt = ax1.scatter(PCA_coord_ILGT[:,0], PCA_coord_ILGT[:,1], 10, ilgt_training_labels, \n",
    "            cmap=plt.cm.coolwarm)\n",
    "\n",
    "cbar = plt.colorbar(pca_plt, )\n",
    "cbar.set_label('Temperature, T')\n",
    "\n",
    "ax1.set_xlabel('PCA component 1')\n",
    "ax1.set_ylabel('PCA component 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xh_GCYflk3VH",
   "metadata": {
    "id": "Xh_GCYflk3VH"
   },
   "source": [
    "### What do you see and what do you think about it?\n",
    "\n",
    "Check the answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-uncle",
   "metadata": {
    "id": "parental-uncle"
   },
   "source": [
    "Wow - by introducing a simple constraint to the Hamiltonian, we broke the PCA. It turns out that going just a little bit outside of the simple models makes straighforward clustering difficult to work. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ziMWHJcolDAo",
   "metadata": {
    "id": "ziMWHJcolDAo"
   },
   "source": [
    "## Extra credit assignment\n",
    "You can go ahead and try more sophisticated method to test the difference between standard Ising model and IGT. One such example is t-Stochastic Neighborhood Embedding (t-SNE). Spoiler alert: it won't help you..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tJ50zvj2g1vZ",
   "metadata": {
    "id": "tJ50zvj2g1vZ"
   },
   "source": [
    "# t-SNE for Ising and Ising with constraints models (SOLUTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WTVPUW-Kg5vl",
   "metadata": {
    "id": "WTVPUW-Kg5vl"
   },
   "outputs": [],
   "source": [
    "# import t-SNE method from skikit learn\n",
    "from sklearn.manifold import TSNE as tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0QrbnGvLhSIK",
   "metadata": {
    "id": "0QrbnGvLhSIK"
   },
   "outputs": [],
   "source": [
    "# the input should be the same as for PCA\n",
    "## Ising model\n",
    "N = ising_training_configs.shape[1] #size of conf\n",
    "########################################################################\n",
    "### TODO: ###\n",
    "########################################################################\n",
    "# flatten the Ising data once again (can copy code from above, of course)\n",
    "# X = ...\n",
    "\n",
    "# repeat for the other data set as well\n",
    "## Ising Gauge Theory model\n",
    "N_igt = ilgt_training_configs[0].shape[0]\n",
    "\n",
    "# X_igt = ...\n",
    "# Ensure that each pixel has zero mean\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bd51db",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_Ising_data = True # easy switch for changing data sets\n",
    "\n",
    "data = X if use_Ising_data else X_igt\n",
    "########################################################################\n",
    "### TODO: ###\n",
    "########################################################################\n",
    "# have a look at the docs of the function tsne() and how to use it\n",
    "# in order to transform <data>. Choose 2 output dimensions once again.\n",
    "# tsne_fits = ...\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ubZ2QVfkhUHN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "id": "ubZ2QVfkhUHN",
    "outputId": "ce377d25-3879-42fe-96ac-1ed5d325a93a"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=200)\n",
    "fig.set_size_inches(3.40457, 3)\n",
    "fig.subplots_adjust(wspace=0.01,hspace=0.01, left=0.20, right=0.9, bottom=0.15, top=0.94)\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "labels = ising_training_labels if use_Ising_data else ilgt_training_labels\n",
    "tsne_plt = ax1.scatter(tsne_fits[:,0], tsne_fits[:,1], 10, labels, \n",
    "            cmap=plt.cm.coolwarm)\n",
    "\n",
    "\n",
    "cbar = plt.colorbar(tsne_plt, )\n",
    "cbar.set_label('Temperature, T')\n",
    "\n",
    "ax1.set_xlabel('tSNE component 1')\n",
    "ax1.set_ylabel('tSNE component 2')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "innovative-change",
    "Nt7BH6snkeXi",
    "Xh_GCYflk3VH",
    "tJ50zvj2g1vZ"
   ],
   "name": "01_Unsupervised_learning_ST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
